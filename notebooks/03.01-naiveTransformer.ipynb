{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4955a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work based on \"TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Dat\" by Tuli et. al. https://arxiv.org/abs/2201.07284\n",
    "# Original implementation https://github.com/imperial-qore/TranAD\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")  # Go up one level to the UROP directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8439a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SEED = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-3\n",
    "\n",
    "# Model hyper-parameters\n",
    "PE_DROPOUT = 0.3\n",
    "TF_DROPOUT = 0.3\n",
    "D_MODEL = 64\n",
    "N_HEAD = 4\n",
    "NUM_LAYERS = 3\n",
    "DIM_FF = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8527d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src import LazyWindowedDataset, train_test_split\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Initialize Dataset\n",
    "full_train_source_dataset = LazyWindowedDataset(\n",
    "    root_dir=\"datasets/RoboticArm\",\n",
    "    split=\"train\",\n",
    "    anomaly_type=['normal'],\n",
    "    domain_type=['source', 'target'],\n",
    "    window_size_ms=100,\n",
    "    stride_ms=50,\n",
    ")\n",
    "\n",
    "train_source_dataset, val_source_dataset = train_test_split(full_train_source_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_source_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "val_loader = DataLoader(val_source_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, drop_last=True)\n",
    "\n",
    "test_source_dataset = LazyWindowedDataset(\n",
    "    root_dir=\"datasets/RoboticArm\",\n",
    "    split=\"test\",\n",
    "    anomaly_type=['normal', 'anomaly'],\n",
    "    domain_type=['source', 'target'],\n",
    "    window_size_ms=100,\n",
    "    stride_ms=50,\n",
    ")\n",
    "test_loader = DataLoader(test_source_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfb913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=6000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model) # [max_len, d_model]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Reshape to [1, max_len, d_model] so it can be broadcast across batch\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len, :]  # Add positional encoding\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, dropout=0.1, pe_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=pe_dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "                                                   batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_proj = nn.Linear(d_model, input_dim)\n",
    "\n",
    "        self.config = {\n",
    "            'input_dim': input_dim,\n",
    "            'd_model': d_model,\n",
    "            'nhead': nhead,\n",
    "            'num_layers': num_layers,\n",
    "            'dim_feedforward': dim_feedforward,\n",
    "            'dropout': dropout,\n",
    "            'pe_dropout': pe_dropout\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.output_proj(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self,):\n",
    "        return self.config\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config(config):\n",
    "        return TimeSeriesTransformer(\n",
    "            input_dim=config['input_dim'],\n",
    "            d_model=config.get('d_model', 64),\n",
    "            nhead=config.get('nhead', 4),\n",
    "            num_layers=config.get('num_layers', 3),\n",
    "            dim_feedforward=config.get('dim_feedforward', 128),\n",
    "            dropout=config.get('dropout', 0.1),\n",
    "            pe_dropout=config.get('pe_dropout', 0.1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd8222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_dim': 7,\n",
    "    'd_model': D_MODEL,\n",
    "    'nhead': N_HEAD,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'dim_feedforward': DIM_FF,\n",
    "    'dropout': TF_DROPOUT,\n",
    "    'pe_dropout': PE_DROPOUT\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TimeSeriesTransformer.from_config(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterior = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72f5d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "TimeSeriesTransformer                         [128, 1600, 7]            --\n",
       "├─Linear: 1-1                                 [128, 1600, 64]           512\n",
       "├─PositionalEncoding: 1-2                     [128, 1600, 64]           --\n",
       "│    └─Dropout: 2-1                           [128, 1600, 64]           --\n",
       "├─TransformerEncoder: 1-3                     [128, 1600, 64]           --\n",
       "│    └─ModuleList: 2-2                        --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-1      [128, 1600, 64]           33,472\n",
       "│    │    └─TransformerEncoderLayer: 3-2      [128, 1600, 64]           33,472\n",
       "│    │    └─TransformerEncoderLayer: 3-3      [128, 1600, 64]           33,472\n",
       "├─Linear: 1-4                                 [128, 1600, 7]            455\n",
       "===============================================================================================\n",
       "Total params: 101,383\n",
       "Trainable params: 101,383\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 6.59\n",
       "===============================================================================================\n",
       "Input size (MB): 5.73\n",
       "Forward/backward pass size (MB): 1689.19\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 1695.13\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(BATCH_SIZE, 1600, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed62ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 50/1712 [00:38<21:06,  1.31batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] (Checkpoint Epoch: 1) | Train Loss: 0.435989 | Val Loss: 0.000000 | Val AUC: 0.0000\n",
      "Time Spent: 38.09s | ETA: 0.00s | Current Time: 2025-05-12 09:10:58\n",
      "Checkpoint saved at checkpoints/abra_TimeSeriesTransformer_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src import train_model, evaluate\n",
    "\n",
    "try:\n",
    "    train_model(\n",
    "        name='abra', \n",
    "        model=model, \n",
    "        criterion=criterior, \n",
    "        optimizer=optimizer, \n",
    "        train_loader=train_loader, \n",
    "        val_loader=None, # Skip validation to speed up\n",
    "        merge_startegy='stack',\n",
    "        num_epochs=1, \n",
    "        verbose=1,\n",
    "        break_at_batch=50,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe6e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 540/540 [02:03<00:00,  4.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall S+T | Loss: 0.0986, AUC: 0.7695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss, auc = evaluate(model, test_loader, criterior, merge_strategy='stack', verbose=True)\n",
    "print(f\"Overall S+T | Loss: {loss:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bd992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
