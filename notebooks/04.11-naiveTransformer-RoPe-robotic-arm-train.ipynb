{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4955a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")  # Go up one level to the UROP directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8439a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SEED = 1\n",
    "TRAIN_BATCH_SIZE = 1 # on-line learning\n",
    "TEST_BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-3\n",
    "\n",
    "# Model hyper-parameters\n",
    "INPUT_DIM = 7\n",
    "TF_DROPOUT = 0.0\n",
    "D_MODEL = 64\n",
    "N_HEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "DIM_FF = 128\n",
    "\n",
    "# Dataset hyper-parameters\n",
    "WINDOW_SIZE_MS=100\n",
    "STRIDE_MS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8527d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src import LazyWindowedDataset, train_test_split\n",
    "\n",
    "# Set generator for reproducibility\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(SEED)\n",
    "torch.manual_seed(generator.initial_seed())\n",
    "\n",
    "# Initialize Dataset\n",
    "full_train_source_dataset = LazyWindowedDataset(\n",
    "    root_dir=\"datasets/RoboticArm\",\n",
    "    split=\"train\",\n",
    "    anomaly_type=['normal'],\n",
    "    domain_type=['source', 'target'],\n",
    "    window_size_ms=WINDOW_SIZE_MS,\n",
    "    stride_ms=STRIDE_MS,\n",
    ")\n",
    "\n",
    "train_source_dataset, val_source_dataset = train_test_split(full_train_source_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_source_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "val_loader = DataLoader(val_source_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, drop_last=True)\n",
    "\n",
    "test_source_dataset = LazyWindowedDataset(\n",
    "    root_dir=\"datasets/RoboticArm\",\n",
    "    split=\"test\",\n",
    "    anomaly_type=['normal', 'anomaly'],\n",
    "    domain_type=['source', 'target'],\n",
    "    window_size_ms=WINDOW_SIZE_MS,\n",
    "    stride_ms=STRIDE_MS,\n",
    ")\n",
    "test_loader = DataLoader(test_source_dataset, batch_size=TEST_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd8222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import RoPeTimeSeriesTransformer\n",
    "\n",
    "config = {\n",
    "    'input_dim': INPUT_DIM,\n",
    "    'd_model': D_MODEL,\n",
    "    'nhead': N_HEAD,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'dim_feedforward': DIM_FF,\n",
    "    'dropout': TF_DROPOUT,\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = RoPeTimeSeriesTransformer.from_config(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterior = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72f5d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "RoPeTimeSeriesTransformer                     [1, 1600, 7]              --\n",
       "├─HybridSensorPositionalEncoding: 1-1         [1, 1600, 7]              --\n",
       "├─Linear: 1-2                                 [1, 1600, 64]             512\n",
       "├─TransformerEncoder: 1-3                     [1, 1600, 64]             --\n",
       "│    └─ModuleList: 2-1                        --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-1      [1, 1600, 64]             33,472\n",
       "│    │    └─TransformerEncoderLayer: 3-2      [1, 1600, 64]             33,472\n",
       "│    │    └─TransformerEncoderLayer: 3-3      [1, 1600, 64]             33,472\n",
       "│    │    └─TransformerEncoderLayer: 3-4      [1, 1600, 64]             33,472\n",
       "├─Linear: 1-4                                 [1, 1600, 7]              455\n",
       "===============================================================================================\n",
       "Total params: 134,855\n",
       "Trainable params: 134,855\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.07\n",
       "===============================================================================================\n",
       "Input size (MB): 0.04\n",
       "Forward/backward pass size (MB): 17.29\n",
       "Params size (MB): 0.27\n",
       "Estimated Total Size (MB): 17.61\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(TRAIN_BATCH_SIZE, 1600, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed62ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 18.99batch/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:01<00:00, 41.72batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] (Checkpoint Epoch: 1) | Train Loss: 0.824327 | Val Loss: 0.760491 | Val AUC: nan\n",
      "Time Spent: 3.85s | ETA: 0.00s | Current Time: 2025-05-22 11:15:56\n",
      "Checkpoint saved at checkpoints/ra_aerodactyl_RoPeTimeSeriesTransformer_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src import train_model, evaluate\n",
    "\n",
    "try:\n",
    "    train_model(\n",
    "        name='ra_aerodactyl', \n",
    "        model=model, \n",
    "        criterion=criterior, \n",
    "        optimizer=optimizer, \n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, # Skip validation to speed up\n",
    "        merge_startegy='stack',\n",
    "        num_epochs=1, \n",
    "        verbose=1,\n",
    "        train_num_batches=50, # Do not train on the whole epoch, but some random choosen batches\n",
    "        val_num_batches=50, # Do not validate on the whole epoch, but some random choosen batches\n",
    "        save_every=1,\n",
    "        generator=generator,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe6e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 540/540 [05:43<00:00,  1.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall S+T | Loss: 0.7622, AUC: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss, auc = evaluate(model, test_loader, criterior, merge_strategy='stack', verbose=True, generator=generator)\n",
    "print(f\"Overall S+T | Loss: {loss:.4f}, AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
