{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import SensorDataset\n",
    "import yaml\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "with open(\"config.yaml\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "sr = config['mic']['sample_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dataset\n",
    "dataset = SensorDataset(\"datasets/BrushlessMotor/train/parquet/mic/\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(dataloader):\n",
    "    print(data.shape)\n",
    "    break\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = librosa.feature.melspectrogram(y=data[0].numpy(), sr=sr)\n",
    "mel_log_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "\n",
    "plt.figure()\n",
    "librosa.display.specshow(mel_log_spectrogram, x_axis='time', y_axis='mel', sr=sr, cmap='plasma')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PerceiverFeatureExtractor, PerceiverForImageClassificationLearned\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "feature_extractor = PerceiverFeatureExtractor.from_pretrained(\"deepmind/vision-perceiver-learned\")\n",
    "model = PerceiverForImageClassificationLearned.from_pretrained(\"deepmind/vision-perceiver-learned\").cuda()\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "display(image)\n",
    "\n",
    "# prepare input\n",
    "encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "inputs = encoding.pixel_values.cuda()\n",
    "# forward pass\n",
    "outputs = model(inputs)\n",
    "logits = outputs.logits\n",
    "print(\"Predicted class:\", model.config.id2label[logits.argmax(-1).item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UROP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
